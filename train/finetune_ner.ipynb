{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9434b4-3c4e-4b55-b8ec-103b72cdb834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boa/.conda/envs/ai/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow._fs.FileInfo size changed, may indicate binary incompatibility. Expected 64 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow._fs.FileSelector size changed, may indicate binary incompatibility. Expected 48 from C header, got 72 from PyObject\n",
      "2024-03-07 14:02:03.736735: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-07 14:02:03.736770: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-07 14:02:03.736807: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-07 14:02:03.743973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edffdfb9-e9f8-4fe1-a9ed-a968442ae35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"boapps/kmdb_entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0745557-be5e-4d5e-a4c1-46a90d71d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O',\n",
    "              'B-NEG-ORG', 'B-POS-ORG',\n",
    "              'I-NEG-ORG', 'I-POS-ORG',\n",
    "              'B-NEG-PER', 'B-POS-PER',\n",
    "              'I-NEG-PER', 'I-POS-PER',\n",
    "              'B-NEG-LOC', 'B-POS-LOC',\n",
    "              'I-NEG-LOC', 'I-POS-LOC',\n",
    "              ]\n",
    "\n",
    "entcolumns = {'ORG': 'institutions', 'LOC': 'places', 'PER': 'people'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f541ee73-aa1b-496a-9581-caf7d503649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88a79ac-66d7-43c4-940b-070ceca9c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anyin(l1, l2):\n",
    "    for e1 in l1:\n",
    "        if e1 in l2:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551e4c89-c94e-4a44-88b2-c00344318d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getsame(e, row):\n",
    "    same = set()\n",
    "    for entity in row['ent_tokens']:\n",
    "        if e in entity['lemma']:\n",
    "            same.add(entity['lemma'])\n",
    "    return list(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9abec6de-8050-4e30-badc-98ba2693e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnertags(row):\n",
    "    for entity in row['ent_tokens']:\n",
    "        if entity['tokens'][0]['ent_type'] in entcolumns:\n",
    "            if anyin(getsame(entity['lemma'], row), row[entcolumns[entity['tokens'][0]['ent_type']]]):\n",
    "                entity['status'] = 'POS'\n",
    "            else:\n",
    "                entity['status'] = 'NEG'\n",
    "    labelbyid = {}\n",
    "    for entity in row['ent_tokens']:\n",
    "        if entity['tokens'][0]['ent_type'] in entcolumns:\n",
    "            for token in entity['tokens']:\n",
    "                labelbyid[token['i']] = token['iob']+'-'+entity['status']+'-'+token['ent_type']\n",
    "    nertags = []\n",
    "    for i, word in enumerate(row['words']):\n",
    "        if i in labelbyid:\n",
    "            nertags.append(label_list.index(labelbyid[i]))\n",
    "        else:\n",
    "            nertags.append(0)\n",
    "    return {'nertags': nertags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d556cc08-ba7a-4656-a095-cd2e40aeec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.map(getnertags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e645514-6fc5-4d44-ae78-efab9d87dfb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example=dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8e450b-f593-4948-a4fb-74eb006bb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('NYTK/PULI-BERT-Large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8381b186-9165-46db-9962-0765b1f0732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(example[\"words\"], is_split_into_words=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21fd51be-6ca8-4cc9-b2f0-7abaa28e2185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'a',\n",
       " 'x',\n",
       " '##i',\n",
       " '.',\n",
       " 'ker',\n",
       " '##ule',\n",
       " '##ti',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " 'tobb',\n",
       " 'mint',\n",
       " 'mas',\n",
       " '##felm',\n",
       " '##ill',\n",
       " '##ia',\n",
       " '##r',\n",
       " '##d',\n",
       " 'forint',\n",
       " '##ert',\n",
       " 'elad',\n",
       " '##ta',\n",
       " 'utols',\n",
       " '##o',\n",
       " ',',\n",
       " '25',\n",
       " 'sza',\n",
       " '##zal',\n",
       " '##ek',\n",
       " '##os',\n",
       " 'u',\n",
       " '##z',\n",
       " '##let',\n",
       " '##resz',\n",
       " '##e',\n",
       " '##t',\n",
       " 'az',\n",
       " 'ob',\n",
       " '##ol',\n",
       " 'x',\n",
       " '##i',\n",
       " '.',\n",
       " 'kft',\n",
       " '.',\n",
       " '-',\n",
       " 'ben',\n",
       " ',',\n",
       " 'amely',\n",
       " 'a',\n",
       " 'la',\n",
       " '##g',\n",
       " '##y',\n",
       " '##man',\n",
       " '##yos',\n",
       " '##i',\n",
       " 'kopasz',\n",
       " '##i',\n",
       " '-',\n",
       " 'g',\n",
       " '##at',\n",
       " 'hasznos',\n",
       " '##itas',\n",
       " '##ara',\n",
       " 'alakult',\n",
       " '.',\n",
       " 'ezzel',\n",
       " 'a',\n",
       " 'ker',\n",
       " '##ule',\n",
       " '##t',\n",
       " 'gyakorlatilag',\n",
       " 'kisz',\n",
       " '##all',\n",
       " '##t',\n",
       " 'abb',\n",
       " '##ol',\n",
       " 'a',\n",
       " 'ceg',\n",
       " '##bol',\n",
       " ',',\n",
       " 'amelyet',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'tam',\n",
       " '##as',\n",
       " 'nagy',\n",
       " '##vall',\n",
       " '##alk',\n",
       " '##ozo',\n",
       " '##val',\n",
       " 'koz',\n",
       " '##ose',\n",
       " '##n',\n",
       " 'alap',\n",
       " '##ito',\n",
       " '##tt',\n",
       " ',',\n",
       " 'es',\n",
       " 'amely',\n",
       " 'a',\n",
       " 'g',\n",
       " '##aton',\n",
       " 'szor',\n",
       " '##ak',\n",
       " '##ozo',\n",
       " '##negyed',\n",
       " '##e',\n",
       " '##t',\n",
       " 'es',\n",
       " 'u',\n",
       " '##dul',\n",
       " '##opa',\n",
       " '##rk',\n",
       " '##ot',\n",
       " 'epi',\n",
       " '##t',\n",
       " 'ki',\n",
       " '.',\n",
       " 'az',\n",
       " 'u',\n",
       " '##z',\n",
       " '##let',\n",
       " '##nek',\n",
       " 'ad',\n",
       " 'egy',\n",
       " 'vaj',\n",
       " '##szin',\n",
       " '##u',\n",
       " 'ar',\n",
       " '##nyal',\n",
       " '##atot',\n",
       " ',',\n",
       " 'hogy',\n",
       " 'uj',\n",
       " '##bud',\n",
       " '##a',\n",
       " ',',\n",
       " 'azaz',\n",
       " 'a',\n",
       " 'x',\n",
       " '##i',\n",
       " '.',\n",
       " 'ker',\n",
       " '##ule',\n",
       " '##t',\n",
       " 'vezet',\n",
       " '##ese',\n",
       " 'hem',\n",
       " '##zse',\n",
       " '##g',\n",
       " 'a',\n",
       " 'fo',\n",
       " '##var',\n",
       " '##osi',\n",
       " 'szinten',\n",
       " 'meghat',\n",
       " '##aro',\n",
       " '##zo',\n",
       " 'part',\n",
       " '##politik',\n",
       " '##usok',\n",
       " '##tol',\n",
       " ':',\n",
       " 'mol',\n",
       " '##na',\n",
       " '##r',\n",
       " 'gy',\n",
       " '##ula',\n",
       " 'ker',\n",
       " '##ule',\n",
       " '##ti',\n",
       " 'polg',\n",
       " '##arm',\n",
       " '##ester',\n",
       " 'az',\n",
       " 'ms',\n",
       " '##z',\n",
       " '##p',\n",
       " 'fo',\n",
       " '##var',\n",
       " '##osi',\n",
       " 'el',\n",
       " '##nok',\n",
       " '##e',\n",
       " ',',\n",
       " 'lakos',\n",
       " 'im',\n",
       " '##re',\n",
       " 'alp',\n",
       " '##olg',\n",
       " '##arm',\n",
       " '##ester',\n",
       " 'pedig',\n",
       " 'az',\n",
       " 'sz',\n",
       " '##ds',\n",
       " '##z',\n",
       " '-',\n",
       " 'ben',\n",
       " 'tol',\n",
       " '##t',\n",
       " 'be',\n",
       " 'hasonl',\n",
       " '##o',\n",
       " 'funk',\n",
       " '##cio',\n",
       " '##t',\n",
       " ',',\n",
       " 'ehhez',\n",
       " 'jo',\n",
       " '##n',\n",
       " 'meg',\n",
       " ',',\n",
       " 'hogy',\n",
       " 'a',\n",
       " 'ber',\n",
       " '##uha',\n",
       " '##za',\n",
       " '##st',\n",
       " 'megv',\n",
       " '##al',\n",
       " '##osi',\n",
       " '##to',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'tam',\n",
       " '##as',\n",
       " 'elet',\n",
       " '##tar',\n",
       " '##sa',\n",
       " ',',\n",
       " 'tut',\n",
       " '##to',\n",
       " 'katal',\n",
       " '##in',\n",
       " ',',\n",
       " 'az',\n",
       " 'ms',\n",
       " '##z',\n",
       " '##p',\n",
       " 'egyik',\n",
       " 'budapesti',\n",
       " 'koz',\n",
       " '##ep',\n",
       " '##vezet',\n",
       " '##oj',\n",
       " '##e',\n",
       " '.',\n",
       " 'az',\n",
       " 'ellen',\n",
       " '##oldali',\n",
       " 'elh',\n",
       " '##arc',\n",
       " '##os',\n",
       " 'sc',\n",
       " '##h',\n",
       " '##nel',\n",
       " '##ler',\n",
       " 'dom',\n",
       " '##onk',\n",
       " '##os',\n",
       " 'viszont',\n",
       " 'az',\n",
       " 'egykori',\n",
       " 'dem',\n",
       " '##szky',\n",
       " '-',\n",
       " 'ka',\n",
       " '##der',\n",
       " ',',\n",
       " 'kes',\n",
       " '##obb',\n",
       " 'kegy',\n",
       " '##veszte',\n",
       " '##tte',\n",
       " 'valt',\n",
       " 'sc',\n",
       " '##h',\n",
       " '##nel',\n",
       " '##ler',\n",
       " 'ist',\n",
       " '##van',\n",
       " 'ex',\n",
       " '##f',\n",
       " '##oe',\n",
       " '##pit',\n",
       " '##esz',\n",
       " 'fia',\n",
       " '.',\n",
       " 'es',\n",
       " 'ki',\n",
       " 'ne',\n",
       " 'hagyjuk',\n",
       " 'az',\n",
       " 'm',\n",
       " '##df',\n",
       " '-',\n",
       " 'et',\n",
       " '!',\n",
       " 'az',\n",
       " 'keddi',\n",
       " 'el',\n",
       " '##oter',\n",
       " '##jeszt',\n",
       " '##est',\n",
       " 'a',\n",
       " 'fidesz',\n",
       " 'es',\n",
       " 'a',\n",
       " 'k',\n",
       " '##d',\n",
       " '##n',\n",
       " '##p',\n",
       " 'egy',\n",
       " '##seg',\n",
       " '##esen',\n",
       " 'elutas',\n",
       " '##ito',\n",
       " '##tta',\n",
       " ',',\n",
       " 'az',\n",
       " 'sz',\n",
       " '##ds',\n",
       " '##z',\n",
       " ',',\n",
       " 'az',\n",
       " 'ms',\n",
       " '##z',\n",
       " '##p',\n",
       " 'es',\n",
       " 'az',\n",
       " 'm',\n",
       " '##df',\n",
       " 'pedig',\n",
       " 'tam',\n",
       " '##ogatta',\n",
       " '.',\n",
       " 'mind',\n",
       " '##ket',\n",
       " 'helyi',\n",
       " 'm',\n",
       " '##df',\n",
       " '-',\n",
       " 'es',\n",
       " 'megszav',\n",
       " '##azt',\n",
       " '##a',\n",
       " 'a',\n",
       " 'javaslatot',\n",
       " ',',\n",
       " 'pedig',\n",
       " 'kora',\n",
       " '##bban',\n",
       " ',',\n",
       " 'amikor',\n",
       " 'az',\n",
       " 'm',\n",
       " '##df',\n",
       " 'alp',\n",
       " '##olg',\n",
       " '##arm',\n",
       " '##estert',\n",
       " 'all',\n",
       " '##ith',\n",
       " '##atott',\n",
       " 'a',\n",
       " 'szocialista',\n",
       " '##k',\n",
       " '##kal',\n",
       " 'es',\n",
       " 'a',\n",
       " 'szabad',\n",
       " 'demokrata',\n",
       " '##k',\n",
       " '##kal',\n",
       " 'koz',\n",
       " '##ose',\n",
       " '##n',\n",
       " 'a',\n",
       " 'test',\n",
       " '##ule',\n",
       " '##t',\n",
       " '##ben',\n",
       " ',',\n",
       " 'a',\n",
       " 'mas',\n",
       " '##ik',\n",
       " 'for',\n",
       " '##um',\n",
       " '##os',\n",
       " 'var',\n",
       " '##osa',\n",
       " '##ty',\n",
       " '##a',\n",
       " 'a',\n",
       " 'fi',\n",
       " '##des',\n",
       " '##szel',\n",
       " 'egy',\n",
       " '##utt',\n",
       " 'kivon',\n",
       " '##ult',\n",
       " 'az',\n",
       " 'u',\n",
       " '##les',\n",
       " '##terem',\n",
       " '##bol',\n",
       " '.',\n",
       " 'a',\n",
       " 'la',\n",
       " '##g',\n",
       " '##y',\n",
       " '##man',\n",
       " '##yos',\n",
       " '##i',\n",
       " 'kopasz',\n",
       " '##i',\n",
       " '-',\n",
       " 'g',\n",
       " '##at',\n",
       " 'forr',\n",
       " '##as',\n",
       " ':',\n",
       " 'google',\n",
       " 'ma',\n",
       " '##p',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " '-',\n",
       " 'ugy',\n",
       " '##ben',\n",
       " 'viszont',\n",
       " 'kep',\n",
       " '##es',\n",
       " 'egy',\n",
       " '##seg',\n",
       " '##esen',\n",
       " 'fol',\n",
       " '##lep',\n",
       " '##ni',\n",
       " 'az',\n",
       " 'm',\n",
       " '##df',\n",
       " '.',\n",
       " 'kerdes',\n",
       " ',',\n",
       " 'hogy',\n",
       " 'ennek',\n",
       " 'mi',\n",
       " 'az',\n",
       " 'oka',\n",
       " '?',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " '##hez',\n",
       " 'kot',\n",
       " '##odik',\n",
       " 'az',\n",
       " 'az',\n",
       " 'm',\n",
       " '##df',\n",
       " '-',\n",
       " 'es',\n",
       " 'or',\n",
       " '##szag',\n",
       " '##g',\n",
       " '##y',\n",
       " '##ule',\n",
       " '##si',\n",
       " 'kep',\n",
       " '##vise',\n",
       " '##lo',\n",
       " ',',\n",
       " 'vas',\n",
       " 'jan',\n",
       " '##os',\n",
       " ',',\n",
       " 'akit',\n",
       " 'a',\n",
       " 'tisztelet',\n",
       " 'tar',\n",
       " '##sa',\n",
       " '##sag',\n",
       " '##a',\n",
       " 'jel',\n",
       " '##olt',\n",
       " 'a',\n",
       " 'magyar',\n",
       " 'demokrata',\n",
       " 'for',\n",
       " '##um',\n",
       " 'parlamenti',\n",
       " 'fr',\n",
       " '##ak',\n",
       " '##cio',\n",
       " '##ja',\n",
       " '##ba',\n",
       " '.',\n",
       " 'a',\n",
       " 'tisztelet',\n",
       " 'tar',\n",
       " '##sa',\n",
       " '##sag',\n",
       " '##at',\n",
       " 'kora',\n",
       " '##bban',\n",
       " 'sc',\n",
       " '##hm',\n",
       " '##uck',\n",
       " 'and',\n",
       " '##orral',\n",
       " 'es',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'tam',\n",
       " '##assal',\n",
       " 'is',\n",
       " 'kapcsolatba',\n",
       " 'hoztak',\n",
       " '.',\n",
       " 'jo',\n",
       " 'volt',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'aj',\n",
       " '##an',\n",
       " '##lata',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " '110',\n",
       " 'milli',\n",
       " '##o',\n",
       " 'forint',\n",
       " 'ert',\n",
       " '##ekben',\n",
       " '1',\n",
       " 'sza',\n",
       " '##zal',\n",
       " '##ek',\n",
       " '##ot',\n",
       " 'meg',\n",
       " 'mindig',\n",
       " 'birtok',\n",
       " '##ol',\n",
       " 'a',\n",
       " 'tar',\n",
       " '##sa',\n",
       " '##sag',\n",
       " '##ban',\n",
       " ',',\n",
       " 'de',\n",
       " 'ez',\n",
       " 'ink',\n",
       " '##abb',\n",
       " 'csak',\n",
       " 'jel',\n",
       " '##kep',\n",
       " '##es',\n",
       " 'tulajdon',\n",
       " '.',\n",
       " 'a',\n",
       " 'ker',\n",
       " '##ule',\n",
       " '##t',\n",
       " 'tobb',\n",
       " 'lep',\n",
       " '##cs',\n",
       " '##obe',\n",
       " '##n',\n",
       " 'vonult',\n",
       " 'ki',\n",
       " 'a',\n",
       " 'ceg',\n",
       " '##bol',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'jav',\n",
       " '##ara',\n",
       " '.',\n",
       " 'ossze',\n",
       " '##sen',\n",
       " 'ket',\n",
       " '##milli',\n",
       " '##ard',\n",
       " 'forintot',\n",
       " 'kapott',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " 'a',\n",
       " 'la',\n",
       " '##g',\n",
       " '##y',\n",
       " '##man',\n",
       " '##yos',\n",
       " '##i',\n",
       " '-',\n",
       " 'ob',\n",
       " '##oler',\n",
       " '##t',\n",
       " ',',\n",
       " 'ahol',\n",
       " 'et',\n",
       " '##terme',\n",
       " '##k',\n",
       " ',',\n",
       " 'viz',\n",
       " '##i',\n",
       " 'szin',\n",
       " '##pad',\n",
       " ',',\n",
       " 'klub',\n",
       " '##helyi',\n",
       " '##seg',\n",
       " '##ek',\n",
       " ',',\n",
       " 'ja',\n",
       " '##cht',\n",
       " '##klub',\n",
       " ',',\n",
       " 'plaz',\n",
       " '##s',\n",
       " 'es',\n",
       " 'meg',\n",
       " 'szam',\n",
       " '##os',\n",
       " 'let',\n",
       " '##esi',\n",
       " '##t',\n",
       " '##meny',\n",
       " 'kesz',\n",
       " '##ul',\n",
       " '.',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'tobb',\n",
       " '##milli',\n",
       " '##ardo',\n",
       " '##s',\n",
       " 'ber',\n",
       " '##uha',\n",
       " '##za',\n",
       " '##st',\n",
       " 'hajtott',\n",
       " 'veg',\n",
       " '##re',\n",
       " 'a',\n",
       " 'ter',\n",
       " '##ule',\n",
       " '##ten',\n",
       " 'es',\n",
       " 'ket',\n",
       " 'szom',\n",
       " '##sze',\n",
       " '##dos',\n",
       " 'tel',\n",
       " '##ket',\n",
       " 'is',\n",
       " 'birtok',\n",
       " '##ol',\n",
       " ',',\n",
       " 'erre',\n",
       " 'hivatkoz',\n",
       " '##ik',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " ',',\n",
       " 'amikor',\n",
       " 'a',\n",
       " 'nagy',\n",
       " '##vall',\n",
       " '##alk',\n",
       " '##ozo',\n",
       " '##val',\n",
       " 'val',\n",
       " '##o',\n",
       " 'tar',\n",
       " '##s',\n",
       " '##ula',\n",
       " '##st',\n",
       " 'magyar',\n",
       " '##azz',\n",
       " '##a',\n",
       " '.',\n",
       " 'a',\n",
       " 'ker',\n",
       " '##ule',\n",
       " '##t',\n",
       " 'illet',\n",
       " '##eke',\n",
       " '##set',\n",
       " '##ol',\n",
       " 'megtud',\n",
       " '##tuk',\n",
       " ',',\n",
       " 'hogy',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " '38',\n",
       " 'sza',\n",
       " '##zal',\n",
       " '##ek',\n",
       " '##os',\n",
       " 'nyer',\n",
       " '##ese',\n",
       " '##g',\n",
       " '##gel',\n",
       " 'szal',\n",
       " '##lt',\n",
       " 'ki',\n",
       " 'az',\n",
       " 'u',\n",
       " '##z',\n",
       " '##let',\n",
       " '##bol',\n",
       " ',',\n",
       " 'es',\n",
       " 'uj',\n",
       " '##bud',\n",
       " '##a',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zata',\n",
       " 'egyeb',\n",
       " '##kent',\n",
       " 'sem',\n",
       " 'ingatlan',\n",
       " '##fejleszt',\n",
       " '##o',\n",
       " ',',\n",
       " 'hogy',\n",
       " 'tov',\n",
       " '##abb',\n",
       " 'var',\n",
       " '##jon',\n",
       " 'a',\n",
       " 'jo',\n",
       " '##vo',\n",
       " '##beni',\n",
       " ',',\n",
       " 'bizonytalan',\n",
       " 'bevet',\n",
       " '##ele',\n",
       " '##kr',\n",
       " '##e',\n",
       " '.',\n",
       " 'szerint',\n",
       " '##uk',\n",
       " 'most',\n",
       " 'volt',\n",
       " 'erd',\n",
       " '##emes',\n",
       " 'kisz',\n",
       " '##all',\n",
       " '##ni',\n",
       " 'a',\n",
       " 'ceg',\n",
       " '##bol',\n",
       " ',',\n",
       " 'es',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " 'ar',\n",
       " '##aja',\n",
       " '##n',\n",
       " '##lata',\n",
       " 'megfelel',\n",
       " '##o',\n",
       " 'volt',\n",
       " '.',\n",
       " 'alacsony',\n",
       " 'volt',\n",
       " 'a',\n",
       " 'vet',\n",
       " '##e',\n",
       " '##lar',\n",
       " 'a',\n",
       " 'fidesz',\n",
       " 'szerint',\n",
       " 'nem',\n",
       " 'ert',\n",
       " 'egyet',\n",
       " 'ezzel',\n",
       " 'az',\n",
       " 'er',\n",
       " '##vele',\n",
       " '##ss',\n",
       " '##e',\n",
       " '##l',\n",
       " 'sc',\n",
       " '##h',\n",
       " '##nel',\n",
       " '##ler',\n",
       " 'dom',\n",
       " '##onk',\n",
       " '##os',\n",
       " ',',\n",
       " 'a',\n",
       " 'fidesz',\n",
       " 'helyi',\n",
       " 'kep',\n",
       " '##vise',\n",
       " '##lo',\n",
       " '##je',\n",
       " ',',\n",
       " 'a',\n",
       " 'fi',\n",
       " '##del',\n",
       " '##itas',\n",
       " 'budapesti',\n",
       " 'el',\n",
       " '##nok',\n",
       " '##e',\n",
       " '.',\n",
       " 'szerinte',\n",
       " 'ar',\n",
       " '##on',\n",
       " 'alul',\n",
       " 'adta',\n",
       " 'el',\n",
       " 'resz',\n",
       " '##ese',\n",
       " '##des',\n",
       " '##e',\n",
       " '##t',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " ',',\n",
       " 'at',\n",
       " '##sza',\n",
       " '##mit',\n",
       " '##va',\n",
       " 'mintegy',\n",
       " '10',\n",
       " '-',\n",
       " '11',\n",
       " '000',\n",
       " 'forintos',\n",
       " 'negy',\n",
       " '##zet',\n",
       " '##mete',\n",
       " '##ra',\n",
       " '##ron',\n",
       " ',',\n",
       " 'ami',\n",
       " 'egyszer',\n",
       " '##uen',\n",
       " 'nevet',\n",
       " '##seg',\n",
       " '##es',\n",
       " 'a',\n",
       " 'folyamatosan',\n",
       " 'fele',\n",
       " '##rt',\n",
       " '##ekel',\n",
       " '##od',\n",
       " '##o',\n",
       " 'del',\n",
       " '-',\n",
       " 'bud',\n",
       " '##an',\n",
       " '.',\n",
       " '(',\n",
       " 'igaz',\n",
       " ',',\n",
       " 'ez',\n",
       " 'a',\n",
       " 'negy',\n",
       " '##zet',\n",
       " '##mete',\n",
       " '##ra',\n",
       " '##r',\n",
       " 'nemi',\n",
       " '##leg',\n",
       " 'megte',\n",
       " '##veszt',\n",
       " '##o',\n",
       " ',',\n",
       " 'mert',\n",
       " 'beles',\n",
       " '##zam',\n",
       " '##ito',\n",
       " '##tta',\n",
       " '##k',\n",
       " 'a',\n",
       " 'la',\n",
       " '##g',\n",
       " '##y',\n",
       " '##man',\n",
       " '##yos',\n",
       " '##i',\n",
       " '-',\n",
       " 'ob',\n",
       " '##ol',\n",
       " 'viz',\n",
       " '##fel',\n",
       " '##ule',\n",
       " '##tet',\n",
       " 'is',\n",
       " '.',\n",
       " ')',\n",
       " 'sc',\n",
       " '##h',\n",
       " '##nel',\n",
       " '##ler',\n",
       " 'szerint',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " 'har',\n",
       " '##om',\n",
       " '##szor',\n",
       " '##os',\n",
       " 'ar',\n",
       " '##on',\n",
       " 'ert',\n",
       " '##eke',\n",
       " '##si',\n",
       " '##th',\n",
       " '##ett',\n",
       " '##e',\n",
       " 'volna',\n",
       " 'a',\n",
       " 'tel',\n",
       " '##kei',\n",
       " '##t',\n",
       " ',',\n",
       " 'ha',\n",
       " 'mar',\n",
       " 'a',\n",
       " 'le',\n",
       " '##iszt',\n",
       " '##inger',\n",
       " '##rel',\n",
       " 'val',\n",
       " '##o',\n",
       " 'tar',\n",
       " '##s',\n",
       " '##ula',\n",
       " '##s',\n",
       " 'ideje',\n",
       " '##n',\n",
       " 'mas',\n",
       " 'felte',\n",
       " '##telek',\n",
       " '##e',\n",
       " '##t',\n",
       " 'szab',\n",
       " 'a',\n",
       " 'vall',\n",
       " '##alk',\n",
       " '##ozo',\n",
       " '##nak',\n",
       " '.',\n",
       " 'a',\n",
       " 'fi',\n",
       " '##del',\n",
       " '##itas',\n",
       " '-',\n",
       " 'vezet',\n",
       " '##o',\n",
       " 'ugy',\n",
       " 'vel',\n",
       " '##i',\n",
       " ',',\n",
       " 'az',\n",
       " 'onk',\n",
       " '##orm',\n",
       " '##any',\n",
       " '##zat',\n",
       " 'ert',\n",
       " '##eken',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4ece16-302d-4b40-8312-66abaa698fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"words\"], truncation=True, is_split_into_words=True, max_length=512)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"nertags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b13368-972c-4241-bbe5-12f445af3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2058873c-0af4-4711-912b-ebd0c556f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a471e90c-b36f-4683-ab17-79c05d4b957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label_list[i] for i in example[f\"nertags\"]]\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9fdb574-0918-4d77-8a34-23335b9a64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96dd03b5-141a-4f34-8e1b-f1d7278a9a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boa/.conda/envs/ai/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of MegatronBertForTokenClassification were not initialized from the model checkpoint at NYTK/PULI-BERT-Large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"NYTK/PULI-BERT-Large\", num_labels=len(label_list), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eda095f-c1c1-478a-a4e8-7052e168a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testvalid = tokenized_dataset['train'].train_test_split()\n",
    "test_valid = train_testvalid['test'].train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d319b7-9319-4fdf-bcb8-bb698739f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboapps\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/boa/autokmdb_bert/wandb/run-20240307_140219-n2dkmdil</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boapps/huggingface/runs/n2dkmdil' target=\"_blank\">firm-serenity-144</a></strong> to <a href='https://wandb.ai/boapps/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boapps/huggingface' target=\"_blank\">https://wandb.ai/boapps/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boapps/huggingface/runs/n2dkmdil' target=\"_blank\">https://wandb.ai/boapps/huggingface/runs/n2dkmdil</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17594' max='17594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17594/17594 6:42:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>0.710177</td>\n",
       "      <td>0.735915</td>\n",
       "      <td>0.722817</td>\n",
       "      <td>0.977626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.052501</td>\n",
       "      <td>0.710769</td>\n",
       "      <td>0.761121</td>\n",
       "      <td>0.735084</td>\n",
       "      <td>0.978752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.051159</td>\n",
       "      <td>0.737493</td>\n",
       "      <td>0.785646</td>\n",
       "      <td>0.760808</td>\n",
       "      <td>0.979839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.049622</td>\n",
       "      <td>0.740180</td>\n",
       "      <td>0.797492</td>\n",
       "      <td>0.767768</td>\n",
       "      <td>0.980325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.047443</td>\n",
       "      <td>0.756677</td>\n",
       "      <td>0.798133</td>\n",
       "      <td>0.776852</td>\n",
       "      <td>0.980924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.046345</td>\n",
       "      <td>0.758800</td>\n",
       "      <td>0.785335</td>\n",
       "      <td>0.771840</td>\n",
       "      <td>0.981286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.789551</td>\n",
       "      <td>0.774101</td>\n",
       "      <td>0.981238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.042805</td>\n",
       "      <td>0.781952</td>\n",
       "      <td>0.805734</td>\n",
       "      <td>0.793665</td>\n",
       "      <td>0.982830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.044339</td>\n",
       "      <td>0.775792</td>\n",
       "      <td>0.815328</td>\n",
       "      <td>0.795068</td>\n",
       "      <td>0.982533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.043091</td>\n",
       "      <td>0.783064</td>\n",
       "      <td>0.812354</td>\n",
       "      <td>0.797440</td>\n",
       "      <td>0.983005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>0.795497</td>\n",
       "      <td>0.816209</td>\n",
       "      <td>0.805720</td>\n",
       "      <td>0.983405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>0.792259</td>\n",
       "      <td>0.817100</td>\n",
       "      <td>0.804488</td>\n",
       "      <td>0.983406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>0.792299</td>\n",
       "      <td>0.821957</td>\n",
       "      <td>0.806856</td>\n",
       "      <td>0.983483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.041060</td>\n",
       "      <td>0.796953</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.808747</td>\n",
       "      <td>0.983787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>0.794618</td>\n",
       "      <td>0.822979</td>\n",
       "      <td>0.808550</td>\n",
       "      <td>0.983758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.040734</td>\n",
       "      <td>0.802341</td>\n",
       "      <td>0.825272</td>\n",
       "      <td>0.813645</td>\n",
       "      <td>0.984165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.040548</td>\n",
       "      <td>0.802303</td>\n",
       "      <td>0.826053</td>\n",
       "      <td>0.814005</td>\n",
       "      <td>0.984164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17594, training_loss=0.04469800686529987, metrics={'train_runtime': 24185.6688, 'train_samples_per_second': 2.91, 'train_steps_per_second': 0.727, 'total_flos': 6.525623837551385e+16, 'train_loss': 0.04469800686529987, 'epoch': 2.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"kmdb_ner_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    #    push_to_hub=True,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_testvalid[\"train\"],\n",
    "    eval_dataset=test_valid[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62e9cc8e-d563-4744-9091-1c27a5bbcc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba85d3e4df354a20901da32d02e35059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709805648.archlinux.2530787.0:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3970e2d4ffe14e759e576e129ba7e32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709806152.archlinux.2534847.0:   0%|          | 0.00/6.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81aa5d6e5890411997875121a25ddc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709809548.archlinux.2534847.1:   0%|          | 0.00/5.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a76affdc18e48b4a3fbe5a71b18f747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709809990.archlinux.2534847.2:   0%|          | 0.00/5.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4041cc24957b499aa7a7efcbf6ccb22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e9d218071416bac837bdb2045a208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 10 LFS files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4731804ca124faf87fe180c576b505e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709811263.archlinux.2569236.0:   0%|          | 0.00/6.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3026318c9c274aa0830e25eaead467ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709811778.archlinux.2572753.0:   0%|          | 0.00/48.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9df50e5b3b849688731b6769bf9a209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709816408.archlinux.2602258.0:   0%|          | 0.00/4.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1997244daaa24978b762084608c80d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709816538.archlinux.2604731.0:   0%|          | 0.00/385k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026f6ad97bb14b6bbb0a6f528873a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/boapps/kmdb_ner_model/commit/cbe054a29f18fb1e28bfd420578fca077b86fb99', commit_message='End of training', commit_description='', oid='cbe054a29f18fb1e28bfd420578fca077b86fb99', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2ba7e-1685-43f9-a8cd-09824043a710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
